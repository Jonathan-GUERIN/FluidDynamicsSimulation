{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\jonat\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.22.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import sqlite3\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sys\n",
    "import datetime, os\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: '/Users/rachadi/Desktop/machine learning PE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-040459ac7cc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tmax'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'alpha'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'stable'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'nb_iteration'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'erreur'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/rachadi/Desktop/machine learning PE'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcnx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'db_diffision1D.db'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mraw_dataset\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT * FROM db_diffusion1D_\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: '/Users/rachadi/Desktop/machine learning PE'"
     ]
    }
   ],
   "source": [
    "columns=['tmax','alpha','dx','dt','stable','nb_iteration','erreur']\n",
    "os.chdir('/Users/rachadi/Desktop/machine learning PE')\n",
    "cnx = sqlite3.connect('db_diffision1D.db')\n",
    "raw_dataset= pd.read_sql_query(\"SELECT * FROM db_diffusion1D_\", cnx)\n",
    "\n",
    "data = raw_dataset.copy()\n",
    "data.columns=['tmax','alpha','dx','dt','stable','nb_iteration','erreur']\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.values\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "data = pd.DataFrame(x_scaled)\n",
    "data.columns = ['tmax','alpha','dx','dt','stable','nb_iteration','erreur']\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data.sample(frac=0.75,random_state=0)\n",
    "test_dataset = data.drop(train_dataset.index)\n",
    "#print(test_dataset.tail())\n",
    "train_labels = train_dataset.pop('dt')\n",
    "test_labels = test_dataset.pop('dt')\n",
    "#print(test_labels.tail() )\n",
    "train_labels = np.asarray(train_labels)\n",
    "test_labels = np.asarray(test_labels)\n",
    "train_dataset = np.asarray(train_dataset)\n",
    "test_dataset = np.asarray(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(10,use_bias=True,input_shape=[train_dataset.shape[1]]))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Dense(10,use_bias=True))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Dense(1,use_bias=True,activation='linear'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "  \n",
    "    \n",
    "  optimizer = tf.optimizers.Adam() #\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mse'])\n",
    "\n",
    "  early_stop = keras.callbacks.EarlyStopping(monitor='val_mse',min_delta=1e-17, patience=10)\n",
    "  logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1,profile_batch=0)\n",
    "\n",
    "\n",
    "  model.fit(train_dataset, \n",
    "            train_labels, \n",
    "            epochs=100,\n",
    "            batch_size=1000,\n",
    "            validation_split = 0.5, \n",
    "            verbose=0, \n",
    "            callbacks=[early_stop,tensorboard_callback])\n",
    "  \n",
    "example_batch = train_dataset[:10]\n",
    "example_result = model.predict(example_batch)\n",
    "print(example_result)\n",
    "print(example_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features).flatten()\n",
    "    #R2\n",
    "    R2=metrics.r2_score(test_labels, predictions)\n",
    "    #Correlation entre predictions et vraies donnees\n",
    "    Correl=np.corrcoef(test_labels, predictions)[0, 1]\n",
    "    print('Model Performance:')\n",
    "    print('Correlation: {:0.4f}.'.format(Correl))\n",
    "    print('R2: {:0.4f}.'.format(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(model, test_features, test_labels):\n",
    "    X_test=test_labels\n",
    "    Y_pred=model.predict(test_features).flatten()\n",
    "    Y_test=test_labels\n",
    "    plt.scatter(Y_test,Y_pred, color = 'red',marker=\".\")\n",
    "    plt.scatter(Y_test,Y_test, color = 'black',marker=\".\")\n",
    "    plt.title('ANN Regression Results')\n",
    "    plt.xlabel('dt_exact')\n",
    "    plt.ylabel('dt_model')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model,test_dataset,test_labels)\n",
    "visualize(model,test_dataset,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
