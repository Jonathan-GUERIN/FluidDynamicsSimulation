{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Importer les bibliothèques utiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import sqlite3\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sys\n",
    "import datetime, os\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Créer le modèle de réseau de neurones ( fonction d'activation = LeakyRelu ) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Définir shape = nombre de features d'entrée ( a changer apres lorsqu'on a la base de donnée ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 500)               11000     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1500)              751500    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1500)              2251500   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 1501      \n",
      "=================================================================\n",
      "Total params: 3,015,501\n",
      "Trainable params: 3,015,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(500,use_bias=True,input_shape=[shape]))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Dense(1500,use_bias=True,input_shape=[shape]))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Dense(1500,use_bias=True,input_shape=[shape]))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(layers.Dense(1,use_bias=True,activation='linear'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Nombre de degré de liberté du réseau : 3 015 501, du meme ordre de la taille de la base de données => Overfitting évité"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Optimiser le réseau, on choisit l'algorithm Adam et 20 000 epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "  \n",
    "    \n",
    "  optimizer = tf.optimizers.Adam() #\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mse'])\n",
    "\n",
    "  early_stop = keras.callbacks.EarlyStopping(monitor='val_mse',min_delta=1e-17, patience=10)\n",
    "  logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1,profile_batch=0)\n",
    "\n",
    "\n",
    "  model.fit(train_dataset, \n",
    "            train_labels, \n",
    "            epochs=20000,\n",
    "            batch_size=1000,\n",
    "            validation_split = 0.5, \n",
    "            verbose=0, \n",
    "            callbacks=[early_stop,tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model()\n",
    "model.save(\"Advection_2D.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
